import os
import sys
import importlib.util
import subprocess
from dotenv import load_dotenv
from openai import OpenAI
import json
import re
import streamlit as st
import pandas as pd
import tempfile
from nexarClient import NexarClient

# æ£€æŸ¥å¹¶å®‰è£…å¿…è¦çš„ä¾èµ–åº“
def check_and_install_dependencies():
    """æ£€æŸ¥å¹¶å®‰è£…å¤„ç†Excelæ–‡ä»¶æ‰€éœ€çš„ä¾èµ–åº“"""
    dependencies = {
        'xlrd': 'xlrd>=2.0.1',      # å¤„ç†æ—§ç‰ˆ .xls æ–‡ä»¶
        'openpyxl': 'openpyxl',     # å¤„ç†æ–°ç‰ˆ .xlsx æ–‡ä»¶
    }
    
    for module, package in dependencies.items():
        if importlib.util.find_spec(module) is None:
            try:
                st.info(f"æ­£åœ¨å®‰è£…ä¾èµ–: {package}...")
                subprocess.check_call([sys.executable, "-m", "pip", "install", package])
                st.success(f"{package} å®‰è£…å®Œæˆ")
            except Exception as e:
                st.error(f"å®‰è£… {package} å¤±è´¥: {e}")
                st.info(f"è¯·æ‰‹åŠ¨å®‰è£…: pip install {package}")

# åœ¨å¯¼å…¥pandasä¹‹å‰æ£€æŸ¥ä¾èµ–
check_and_install_dependencies()

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# DeepSeek API é…ç½®
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
DEEPSEEK_BASE_URL = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
if not DEEPSEEK_API_KEY:
    raise ValueError("é”™è¯¯ï¼šæœªæ‰¾åˆ° DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡ã€‚")
deepseek_client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASE_URL)

# Nexar API é…ç½®
NEXAR_CLIENT_ID = os.getenv("NEXAR_CLIENT_ID")
NEXAR_CLIENT_SECRET = os.getenv("NEXAR_CLIENT_SECRET")
if not NEXAR_CLIENT_ID or not NEXAR_CLIENT_SECRET:
    raise ValueError("é”™è¯¯ï¼šæœªæ‰¾åˆ° NEXAR_CLIENT_ID æˆ– NEXAR_CLIENT_SECRET ç¯å¢ƒå˜é‡ã€‚")
nexar_client = NexarClient(NEXAR_CLIENT_ID, NEXAR_CLIENT_SECRET)

# GraphQL æŸ¥è¯¢
QUERY_ALTERNATIVE_PARTS = '''
query findAlternativeParts($q: String!, $limit: Int = 10) {
  supSearchMpn(q: $q, limit: $limit) {
    hits
    results {
      part {
        similarParts {
          name
          mpn
          octopartUrl
        }
      }
    }
  }
}
'''

def get_nexar_alternatives(mpn: str, limit: int = 10):
    variables = {"q": mpn, "limit": limit}
    try:
        data = nexar_client.get_query(QUERY_ALTERNATIVE_PARTS, variables)
        alternative_parts = []
        
        # æ·»åŠ æ•°æ®æœ‰æ•ˆæ€§æ£€æŸ¥ä¸è°ƒè¯•ä¿¡æ¯
        if not data:
            st.warning(f"Nexar API æœªè¿”å›æœ‰æ•ˆæ•°æ®ï¼Œå¯èƒ½æ˜¯æŸ¥è¯¢ '{mpn}' æ— ç»“æœ")
            return []
            
        # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        with st.sidebar.expander(f"Nexar API è°ƒè¯•ä¿¡æ¯ - {mpn}", expanded=False):
            st.write(f"**åŸå§‹Nexar APIå“åº”ç»“æ„:**")
            st.write(data)
            
        # å®Œå…¨é‡å†™æ•°æ®æå–é€»è¾‘ï¼Œä»¥æ›´å¥å£®çš„æ–¹å¼å¤„ç†å„ç§å¯èƒ½çš„ç»“æ„
        if isinstance(data, dict):
            # å°è¯•ä»ä¸åŒä½ç½®æå–æ•°æ®
            sup_search = data.get("supSearchMpn", {})
            
            # å¦‚æœsupSearchMpnæ˜¯å­—å…¸
            if isinstance(sup_search, dict):
                results = sup_search.get("results", [])
                
                # å¦‚æœresultsæ˜¯åˆ—è¡¨
                if isinstance(results, list):
                    # æ­£å¸¸å¤„ç†
                    for result in results:
                        if not isinstance(result, dict):
                            continue
                            
                        part = result.get("part", {})
                        if not isinstance(part, dict):
                            continue
                            
                        similar_parts = part.get("similarParts", [])
                        if not isinstance(similar_parts, list):
                            continue
                            
                        for similar in similar_parts:
                            if not isinstance(similar, dict):
                                continue
                                
                            alternative_parts.append({
                                "name": similar.get("name", ""),
                                "mpn": similar.get("mpn", ""),
                                "octopartUrl": similar.get("octopartUrl", "")
                            })
                else:
                    # å¦‚æœresultsä¸æ˜¯åˆ—è¡¨ï¼Œå°è¯•å…¶ä»–æ•°æ®ç»“æ„
                    st.warning(f"Nexar API è¿”å›äº†éæ ‡å‡†ç»“æ„çš„æ•°æ® (resultsä¸æ˜¯åˆ—è¡¨)")
                    
                    # å°è¯•ç›´æ¥ä»é¡¶å±‚æå–æ•°æ®
                    parts_data = []
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰ç›´æ¥çš„partå­—æ®µ
                    if "part" in sup_search:
                        part = sup_search.get("part", {})
                        if isinstance(part, dict) and "similarParts" in part:
                            parts_data = part.get("similarParts", [])
                    
                    # å¦‚æœæ‰¾åˆ°ç–‘ä¼¼éƒ¨ä»¶æ•°æ®
                    if isinstance(parts_data, list):
                        for part_item in parts_data:
                            if not isinstance(part_item, dict):
                                continue
                                
                            alternative_parts.append({
                                "name": part_item.get("name", "æœªçŸ¥åç§°"),
                                "mpn": part_item.get("mpn", "æœªçŸ¥å‹å·"),
                                "octopartUrl": part_item.get("octopartUrl", "https://example.com")
                            })
            else:
                st.warning(f"Nexar API è¿”å›äº†éæ ‡å‡†ç»“æ„ (supSearchMpnä¸æ˜¯å­—å…¸)")
                # å°è¯•ä»æ•´ä¸ªå“åº”ä¸­æ‰¾åˆ°ä»»ä½•å¯èƒ½çš„éƒ¨ä»¶ä¿¡æ¯
                for key, value in data.items():
                    if isinstance(value, dict) and "parts" in value:
                        parts = value.get("parts", [])
                        if isinstance(parts, list):
                            for part in parts:
                                if not isinstance(part, dict):
                                    continue
                                alternative_parts.append({
                                    "name": part.get("name", "æœªçŸ¥åç§°"),
                                    "mpn": part.get("mpn", "æœªçŸ¥å‹å·"),
                                    "octopartUrl": "https://example.com"
                                })
        
        # å¦‚æœæ— æ³•æ‰¾åˆ°ä»»ä½•æ›¿ä»£ä»¶
        if not alternative_parts:
            st.info(f"Nexar API æœªèƒ½ä¸º '{mpn}' æ‰¾åˆ°æ›¿ä»£å…ƒå™¨ä»¶")
            
            # åˆ›å»ºä¸€ä¸ªå‡æ•°æ®ç”¨äºæµ‹è¯•å…¶ä»–éƒ¨åˆ†çš„åŠŸèƒ½
            if st.session_state.get("use_dummy_data", False):
                st.info("ä½¿ç”¨æµ‹è¯•æ•°æ®ç»§ç»­æŸ¥è¯¢")
                alternative_parts = [
                    {
                        "name": f"ç±»ä¼¼å…ƒä»¶: {mpn}æ›¿ä»£å“1",
                        "mpn": f"{mpn}_ALT1",
                        "octopartUrl": "https://www.octopart.com"
                    },
                    {
                        "name": f"ç±»ä¼¼å…ƒä»¶: {mpn}æ›¿ä»£å“2",
                        "mpn": f"{mpn}_ALT2",
                        "octopartUrl": "https://www.octopart.com"
                    }
                ]
            
        return alternative_parts
        
    except Exception as e:
        st.error(f"Nexar API æŸ¥è¯¢å¤±è´¥: {e}")
        import traceback
        with st.sidebar.expander("Nexar APIé”™è¯¯è¯¦æƒ…", expanded=False):
            st.code(traceback.format_exc())
        return []

def is_domestic_brand(model_name):
    domestic_brands = [
        "GigaDevice", "å…†æ˜“åˆ›æ–°", "WCH", "æ²æ’", "Fudan Micro", "å¤æ—¦å¾®ç”µå­",
        "Zhongying", "ä¸­é¢–ç”µå­", "SG Micro", "åœ£é‚¦å¾®ç”µå­", "LD", "LDO", "SG", "SGC",
        "APM", "AP", "BL", "BYD", "CETC", "CR Micro", "CR", "HuaDa", "HuaHong",
        "SGM", "BLD", "EUTECH", "EUTECH Micro", "3PEAK", "Chipsea", "Chipown"
    ]
    # æ›´å®½æ¾çš„åŒ¹é…ï¼šæ£€æŸ¥å‹å·æ˜¯å¦ä»¥å›½äº§å“ç‰Œçš„å¸¸è§å‰ç¼€å¼€å¤´æˆ–åŒ…å«å“ç‰Œå
    return any(model_name.lower().startswith(brand.lower()) for brand in domestic_brands) or \
           any(brand.lower() in model_name.lower() for brand in domestic_brands)

def extract_json_content(content, call_type="åˆæ¬¡è°ƒç”¨"):
    # è®°å½•åŸå§‹å†…å®¹ä»¥ä¾¿è°ƒè¯•
    with st.sidebar.expander(f"è°ƒè¯•ä¿¡æ¯ - åŸå§‹å“åº” ({call_type})", expanded=False):
        st.write(f"**å°è¯•è§£æçš„åŸå§‹å“åº”å†…å®¹ ({call_type}):**")
        st.code(content, language="text")

    # å¤„ç†ç©ºå“åº”
    if not content or content.strip() == "":
        st.warning(f"{call_type} è¿”å›äº†ç©ºå“åº”")
        return []

    # ç›´æ¥å°è¯•è§£æ JSON
    try:
        parsed = json.loads(content)
        # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ—è¡¨
        if not isinstance(parsed, list):
            raise ValueError("å“åº”ä¸æ˜¯ JSON æ•°ç»„")
        # è¡¥å…¨ç¼ºå°‘çš„å­—æ®µ
        for item in parsed:
            # ç¡®ä¿åŸºæœ¬å­—æ®µå­˜åœ¨
            item["model"] = item.get("model", "æœªçŸ¥å‹å·")
            item["brand"] = item.get("brand", "æœªçŸ¥å“ç‰Œ")
            item["parameters"] = item.get("parameters", "å‚æ•°æœªçŸ¥")
            item["type"] = item.get("type", "æœªçŸ¥")
            item["datasheet"] = item.get("datasheet", "https://www.example.com/datasheet")
            
            # ç¡®ä¿æ–°å¢å­—æ®µå­˜åœ¨
            item["category"] = item.get("category", "æœªçŸ¥ç±»åˆ«")
            item["package"] = item.get("package", "æœªçŸ¥å°è£…")
            
        return parsed
    except json.JSONDecodeError:
        pass

    # å°è¯•æå–ä»£ç å—ä¸­çš„ JSON
    code_block_pattern = r"```(?:json)?\s*\n?([\s\S]*?)\n?```"
    code_match = re.search(code_block_pattern, content, re.DOTALL)
    if (code_match):
        json_content = code_match.group(1).strip()
        try:
            parsed = json.loads(json_content)
            for item in parsed:
                # ç¡®ä¿åŸºæœ¬å­—æ®µå­˜åœ¨
                item["model"] = item.get("model", "æœªçŸ¥å‹å·")
                item["brand"] = item.get("brand", "æœªçŸ¥å“ç‰Œ")
                item["parameters"] = item.get("parameters", "å‚æ•°æœªçŸ¥")
                item["type"] = item.get("type", "æœªçŸ¥")
                item["datasheet"] = item.get("datasheet", "https://www.example.com/datasheet")
                
                # ç¡®ä¿æ–°å¢å­—æ®µå­˜åœ¨
                item["category"] = item.get("category", "æœªçŸ¥ç±»åˆ«")
                item["package"] = item.get("package", "æœªçŸ¥å°è£…")
                
            return parsed
        except json.JSONDecodeError:
            pass

    # å°è¯•æå–è£¸ JSON æ•°ç»„
    json_match = re.search(r'\[\s*\{.*\}\s*\]', content, re.DOTALL)
    if json_match:
        try:
            parsed = json.loads(json_match.group(0))
            for item in parsed:
                if not all(key in item for key in ["model", "parameters", "type", "datasheet"]):
                    item["model"] = item.get("model", "æœªçŸ¥å‹å·")
                    item["parameters"] = item.get("parameters", "å‚æ•°æœªçŸ¥")
                    item["type"] = item.get("type", "æœªçŸ¥")
                    item["datasheet"] = item.get("datasheet", "https://www.example.com/datasheet")
                # ç¡®ä¿å“ç‰Œå­—æ®µå­˜åœ¨
                if "brand" not in item:
                    item["brand"] = item.get("brand", "æœªçŸ¥å“ç‰Œ")
                # ç¡®ä¿æ–°å¢å­—æ®µå­˜åœ¨
                item["category"] = item.get("category", "æœªçŸ¥ç±»åˆ«")
                item["package"] = item.get("package", "æœªçŸ¥å°è£…")
            return parsed
        except json.JSONDecodeError:
            pass

    # å°è¯•é€è¡Œè§£æï¼Œå¤„ç†å¯èƒ½çš„å¤šè¡Œ JSON
    lines = content.strip().split('\n')
    json_content = ''
    in_json = False
    for line in lines:
        line = line.strip()
        if line.startswith('[') or in_json:
            json_content += line
            in_json = True
        if line.endswith(']'):
            break
    if json_content:
        try:
            parsed = json.loads(json_content)
            for item in parsed:
                if not all(key in item for key in ["model", "parameters", "type", "datasheet"]):
                    item["model"] = item.get("model", "æœªçŸ¥å‹å·")
                    item["parameters"] = item.get("parameters", "å‚æ•°æœªçŸ¥")
                    item["type"] = item.get("type", "æœªçŸ¥")
                    item["datasheet"] = item.get("datasheet", "https://www.example.com/datasheet")
                # ç¡®ä¿å“ç‰Œå­—æ®µå­˜åœ¨
                if "brand" not in item:
                    item["brand"] = item.get("brand", "æœªçŸ¥å“ç‰Œ")
                # ç¡®ä¿æ–°å¢å­—æ®µå­˜åœ¨
                item["category"] = item.get("category", "æœªçŸ¥ç±»åˆ«")
                item["package"] = item.get("package", "æœªçŸ¥å°è£…")
            return parsed
        except json.JSONDecodeError:
            pass

    # æ·»åŠ æ›´å¼ºå¤§çš„JSONæå–å¤„ç†ï¼Œå¤„ç†æ›´å¤šè¾¹ç¼˜æƒ…å†µ
    # å°è¯•ä»æ–‡æœ¬ä¸­æŠ½å–ä»»ä½•çœ‹èµ·æ¥åƒJSONå¯¹è±¡çš„å†…å®¹
    possible_json_pattern = r'\[\s*\{\s*"model"\s*:.*?\}\s*\]'
    json_fragments = re.findall(possible_json_pattern, content, re.DOTALL)
    
    for fragment in json_fragments:
        try:
            parsed = json.loads(fragment)
            # è¡¥å…¨ç¼ºå°‘çš„å­—æ®µ
            for item in parsed:
                if not all(key in item for key in ["model", "parameters", "type", "datasheet"]):
                    item["model"] = item.get("model", "æœªçŸ¥å‹å·")
                    item["parameters"] = item.get("parameters", "å‚æ•°æœªçŸ¥")
                    item["type"] = item.get("type", "æœªçŸ¥")
                    item["datasheet"] = item.get("datasheet", "https://www.example.com/datasheet")
                # ç¡®ä¿å“ç‰Œå­—æ®µå­˜åœ¨
                if "brand" not in item:
                    item["brand"] = item.get("brand", "æœªçŸ¥å“ç‰Œ")
                # ç¡®ä¿æ–°å¢å­—æ®µå­˜åœ¨
                item["category"] = item.get("category", "æœªçŸ¥ç±»åˆ«")
                item["package"] = item.get("package", "æœªçŸ¥å°è£…")
            return parsed
        except json.JSONDecodeError:
            pass
            
    # å¦‚æœä¸Šé¢æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é”™è¯¯
    for fix_attempt in [
        lambda c: c.replace("'", '"'),  # å•å¼•å·æ›¿æ¢ä¸ºåŒå¼•å·
        lambda c: re.sub(r'",\s*\}', '"}', c),  # ä¿®å¤å°¾éƒ¨å¤šä½™é€—å·
        lambda c: re.sub(r',\s*]', ']', c)  # ä¿®å¤æ•°ç»„å°¾éƒ¨å¤šä½™é€—å·
    ]:
        try:
            fixed_content = fix_attempt(content)
            parsed = json.loads(fixed_content)
            if isinstance(parsed, list):
                for item in parsed:
                    if not all(key in item for key in ["model", "parameters", "type", "datasheet"]):
                        item["model"] = item.get("model", "æœªçŸ¥å‹å·")
                        item["parameters"] = item.get("parameters", "å‚æ•°æœªçŸ¥")
                        item["type"] = item.get("type", "æœªçŸ¥")
                        item["datasheet"] = item.get("datasheet", "https://www.example.com/datasheet")
                    # ç¡®ä¿å“ç‰Œå­—æ®µå­˜åœ¨
                    if "brand" not in item:
                        item["brand"] = item.get("brand", "æœªçŸ¥å“ç‰Œ")
                    # ç¡®ä¿æ–°å¢å­—æ®µå­˜åœ¨
                    item["category"] = item.get("category", "æœªçŸ¥ç±»åˆ«")
                    item["package"] = item.get("package", "æœªçŸ¥å°è£…")
                return parsed
        except:
            pass

    st.error(f"æ— æ³•ä»APIå“åº”ä¸­æå–æœ‰æ•ˆçš„JSONå†…å®¹ ({call_type})")
    return []

def get_alternative_parts(part_number):
    # Step 1: è·å– Nexar API çš„æ›¿ä»£å…ƒå™¨ä»¶æ•°æ®
    nexar_alternatives = get_nexar_alternatives(part_number, limit=10)
    context = "Nexar API æä¾›çš„æ›¿ä»£å…ƒå™¨ä»¶æ•°æ®ï¼š\n"
    if (nexar_alternatives):
        for i, alt in enumerate(nexar_alternatives, 1):
            context += f"{i}. å‹å·: {alt['mpn']}, åç§°: {alt['name']}, é“¾æ¥: {alt['octopartUrl']}\n"
    else:
        st.warning("âš ï¸ Nexar API æœªè¿”å›æ•°æ®ï¼Œå°†ç›´æ¥ä½¿ç”¨ DeepSeek æ¨èã€‚")
        context = "æ—  Nexar API æ•°æ®å¯ç”¨ï¼Œè¯·ç›´æ¥æ¨èæ›¿ä»£å…ƒå™¨ä»¶ã€‚\n"

    # Step 2: æ„é€  DeepSeek API çš„æç¤ºè¯
    prompt = f"""
    ä»»åŠ¡ï¼šä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”µå­å…ƒå™¨ä»¶é¡¾é—®ï¼Œä¸“ç²¾äºå›½äº§æ›¿ä»£æ–¹æ¡ˆã€‚ä»¥ä¸‹æ˜¯ Nexar API æä¾›çš„æ›¿ä»£å…ƒå™¨ä»¶æ•°æ®ï¼Œè¯·ç»“åˆè¿™äº›æ•°æ®ä¸ºè¾“å…¥å…ƒå™¨ä»¶æ¨èæ›¿ä»£äº§å“ã€‚æ¨èçš„æ›¿ä»£æ–¹æ¡ˆå¿…é¡»ä¸è¾“å…¥å‹å· {part_number} ä¸åŒï¼ˆç»å¯¹ä¸èƒ½æ¨è {part_number} æˆ–å…¶å˜ä½“ï¼Œå¦‚ {part_number} çš„ä¸åŒå°è£…ï¼‰ã€‚

    è¾“å…¥å…ƒå™¨ä»¶å‹å·ï¼š{part_number}

    {context}

    è¦æ±‚ï¼š
    1. å¿…é¡»æ¨èè‡³å°‘ä¸€ç§ä¸­å›½å¤§é™†æœ¬åœŸå“ç‰Œçš„æ›¿ä»£æ–¹æ¡ˆï¼ˆå¦‚ GigaDevice/å…†æ˜“åˆ›æ–°ã€WCH/æ²æ’ã€å¤æ—¦å¾®ç”µå­ã€ä¸­é¢–ç”µå­ã€åœ£é‚¦å¾®ç”µå­ç­‰ï¼‰
    2. å¦‚æœèƒ½æ‰¾åˆ°å¤šç§ä¸­å›½å¤§é™†æœ¬åœŸå“ç‰Œçš„æ›¿ä»£äº§å“ï¼Œä¼˜å…ˆæ¨èè¿™äº›äº§å“ï¼Œæ¨èçš„å›½äº§æ–¹æ¡ˆæ•°é‡è¶Šå¤šè¶Šå¥½
    3. å¦‚æœå®åœ¨æ‰¾ä¸åˆ°è¶³å¤Ÿä¸‰ç§ä¸­å›½å¤§é™†æœ¬åœŸå“ç‰Œçš„äº§å“ï¼Œå¯ä»¥æ¨èå›½å¤–å“ç‰Œäº§å“ä½œä¸ºè¡¥å……ï¼Œä½†å¿…é¡»æ˜ç¡®æ ‡æ³¨
    4. æ€»å…±éœ€è¦æ¨è 3 ç§æ€§èƒ½ç›¸è¿‘çš„æ›¿ä»£å‹å·
    5. æä¾›æ¯ç§å‹å·çš„å“ç‰Œåç§°ã€å°è£…ä¿¡æ¯å’Œå…ƒå™¨ä»¶ç±»ç›®ï¼ˆä¾‹å¦‚ï¼šMCUã€DCDCã€LDOã€ä¼ æ„Ÿå™¨ã€å­˜å‚¨èŠ¯ç‰‡ç­‰ï¼‰
    6. æ ¹æ®å…ƒå™¨ä»¶ç±»å‹æä¾›ä¸åŒçš„å…³é”®å‚æ•°ï¼š
       - è‹¥æ˜¯MCU/å•ç‰‡æœºï¼šæä¾›CPUå†…æ ¸ã€ä¸»é¢‘ã€ç¨‹åºå­˜å‚¨å®¹é‡ã€RAMå¤§å°ã€IOæ•°é‡
       - è‹¥æ˜¯DCDCï¼šæä¾›è¾“å…¥ç”µå‹èŒƒå›´ã€è¾“å‡ºç”µå‹ã€æœ€å¤§è¾“å‡ºç”µæµã€æ•ˆç‡
       - è‹¥æ˜¯LDOï¼šæä¾›è¾“å…¥ç”µå‹èŒƒå›´ã€è¾“å‡ºç”µå‹ã€æœ€å¤§è¾“å‡ºç”µæµã€å‹å·®
       - è‹¥æ˜¯å­˜å‚¨å™¨ï¼šæä¾›å®¹é‡ã€æ¥å£ç±»å‹ã€è¯»å†™é€Ÿåº¦
       - è‹¥æ˜¯ä¼ æ„Ÿå™¨ï¼šæä¾›æµ‹é‡èŒƒå›´ã€ç²¾åº¦ã€æ¥å£ç±»å‹
       - å…¶ä»–ç±»å‹æä¾›å¯¹åº”çš„å…³é”®å‚æ•°
    7. åœ¨æ¯ä¸ªæ¨èæ–¹æ¡ˆä¸­æ˜ç¡®æ ‡æ³¨æ˜¯"å›½äº§"è¿˜æ˜¯"è¿›å£"äº§å“
    8. æä¾›äº§å“å®˜ç½‘é“¾æ¥ï¼ˆè‹¥æ— çœŸå®é“¾æ¥ï¼Œå¯æä¾›ç¤ºä¾‹é“¾æ¥ï¼Œå¦‚ https://www.example.com/datasheetï¼‰
    9. æ¨èçš„å‹å·ä¸èƒ½ä¸è¾“å…¥å‹å· {part_number} ç›¸åŒ
    10. å¿…é¡»ä¸¥æ ¼è¿”å›ä»¥ä¸‹ JSON æ ¼å¼çš„ç»“æœï¼Œä¸å…è®¸æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜ã€Markdown æ ¼å¼æˆ–ä»£ç å—æ ‡è®°ï¼ˆå³ä¸è¦ä½¿ç”¨ ```json æˆ–å…¶ä»–æ ‡è®°ï¼‰ï¼Œç›´æ¥è¿”å›è£¸ JSONï¼š
    [
        {{"model": "SG1117-1.2", "brand": "SG Micro/åœ£é‚¦å¾®ç”µå­", "category": "LDO", "package": "DPAK", "parameters": "è¾“å…¥ç”µå‹: 2.0-12V, è¾“å‡ºç”µå‹: 1.2V, è¾“å‡ºç”µæµ: 800mA, å‹å·®: 1.1V", "type": "å›½äº§", "datasheet": "https://www.sgmicro.com/datasheet"}},
        {{"model": "GD32F103C8T6", "brand": "GigaDevice/å…†æ˜“åˆ›æ–°", "category": "MCU", "package": "LQFP48", "parameters": "CPUå†…æ ¸: ARM Cortex-M3, ä¸»é¢‘: 72MHz, Flash: 64KB, RAM: 20KB, IO: 37", "type": "å›½äº§", "datasheet": "https://www.gigadevice.com/datasheet"}},
        {{"model": "MP2307DN", "brand": "MPS/èŠ¯æºç³»ç»Ÿ", "category": "DCDC", "package": "SOIC-8", "parameters": "è¾“å…¥ç”µå‹: 4.75-23V, è¾“å‡ºç”µå‹: 0.925-20V, è¾“å‡ºç”µæµ: 3A, æ•ˆç‡: 95%", "type": "è¿›å£", "datasheet": "https://www.monolithicpower.com/datasheet"}}
    ]
    """

    try:
        response = deepseek_client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç²¾é€šä¸­å›½ç”µå­å…ƒå™¨ä»¶è¡Œä¸šçš„ä¸“å®¶ï¼Œæ“…é•¿ä¸ºå„ç§å…ƒå™¨ä»¶å¯»æ‰¾åˆé€‚çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå°¤å…¶ä¸“æ³¨äºä¸­å›½å¤§é™†æœ¬åœŸç”Ÿäº§çš„å›½äº§å…ƒå™¨ä»¶ã€‚å§‹ç»ˆä»¥æœ‰æ•ˆçš„JSONæ ¼å¼å›å¤ï¼Œä¸æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜ã€‚"},
                {"role": "user", "content": prompt}
            ],
            stream=False,
            max_tokens=1000
        )
        raw_content = response.choices[0].message.content
        recommendations = extract_json_content(raw_content, "åˆæ¬¡è°ƒç”¨")

        # Step 3: è¿‡æ»¤æ‰ä¸è¾“å…¥å‹å·ç›¸åŒçš„æ¨è
        recommendations = [rec for rec in recommendations if rec["model"].lower() != part_number.lower()]

        # Step 4: å¦‚æœæ¨èæ•°é‡ä¸è¶³ï¼Œä» Nexar æ•°æ®ä¸­è¡¥å……
        if len(recommendations) < 3 and nexar_alternatives:
            for alt in nexar_alternatives:
                if len(recommendations) >= 3:
                    break
                if alt["mpn"].lower() != part_number.lower():
                    recommendations.append({
                        "model": alt["mpn"],
                        "brand": alt.get("name", "æœªçŸ¥å“ç‰Œ").split(' ')[0] if alt.get("name") else "æœªçŸ¥å“ç‰Œ",
                        "category": "æœªçŸ¥ç±»åˆ«",
                        "package": "æœªçŸ¥å°è£…",
                        "parameters": "å‚æ•°æœªçŸ¥",
                        "type": "æœªçŸ¥",
                        "datasheet": alt["octopartUrl"]
                    })

        # Step 5: åå¤„ç†ï¼Œè¯†åˆ«å›½äº§æ–¹æ¡ˆ
        for rec in recommendations:
            if rec["type"] == "æœªçŸ¥" and is_domestic_brand(rec["model"]):
                rec["type"] = "å›½äº§"

        # Step 6: å¦‚æœä»ç„¶ä¸è¶³ 3 ä¸ªï¼Œæˆ–ç¼ºå°‘å›½äº§æ–¹æ¡ˆï¼Œé‡æ–°è°ƒç”¨ DeepSeek å¼ºè°ƒå›½äº§ä¼˜å…ˆ
        need_second_query = len(recommendations) < 3 or not any(rec["type"] == "å›½äº§" for rec in recommendations)
        
        if need_second_query:
            st.warning("âš ï¸ æ¨èç»“æœä¸è¶³æˆ–æœªåŒ…å«å›½äº§æ–¹æ¡ˆï¼Œå°†é‡æ–°è°ƒç”¨ DeepSeek æ¨èã€‚")
            
            prompt_retry = f"""
            ä»»åŠ¡ï¼šä¸ºä»¥ä¸‹å…ƒå™¨ä»¶æ¨èæ›¿ä»£äº§å“ï¼Œæ¨èçš„æ›¿ä»£æ–¹æ¡ˆå¿…é¡»ä¸è¾“å…¥å‹å· {part_number} ä¸åŒï¼ˆç»å¯¹ä¸èƒ½æ¨è {part_number} æˆ–å…¶å˜ä½“ï¼Œå¦‚ {part_number} çš„ä¸åŒå°è£…ï¼‰ã€‚
            è¾“å…¥å…ƒå™¨ä»¶å‹å·ï¼š{part_number}

            ä¹‹å‰çš„æ¨èç»“æœæœªåŒ…å«å›½äº§æ–¹æ¡ˆæˆ–æ•°é‡ä¸è¶³ï¼Œè¯·é‡æ–°æ¨èï¼Œé‡ç‚¹å…³æ³¨å›½äº§æ›¿ä»£æ–¹æ¡ˆã€‚

            è¦æ±‚ï¼š
            1. å¿…é¡»æ¨èè‡³å°‘ä¸€ç§ä¸­å›½å¤§é™†æœ¬åœŸå“ç‰Œçš„æ›¿ä»£æ–¹æ¡ˆï¼ˆå¦‚ GigaDevice/å…†æ˜“åˆ›æ–°ã€WCH/æ²æ’ã€å¤æ—¦å¾®ç”µå­ã€ä¸­é¢–ç”µå­ã€åœ£é‚¦å¾®ç”µå­ã€3PEAKã€Chipsea ç­‰ï¼‰
            2. ä¼˜å…ˆæ¨èå›½äº§èŠ¯ç‰‡ï¼Œæ¨èçš„å›½äº§æ–¹æ¡ˆæ•°é‡è¶Šå¤šè¶Šå¥½
            3. å¦‚æœæ‰¾ä¸åˆ°è¶³å¤Ÿçš„å›½äº§æ–¹æ¡ˆï¼Œå¯ä»¥è¡¥å……è¿›å£æ–¹æ¡ˆï¼Œä½†å¿…é¡»æ˜ç¡®æ ‡æ³¨
            4. æ€»å…±æ¨è {3 - len(recommendations)} ç§æ›¿ä»£æ–¹æ¡ˆ
            5. æä¾›æ¯ç§å‹å·çš„å“ç‰Œåç§°ã€å°è£…ä¿¡æ¯å’Œå…ƒå™¨ä»¶ç±»ç›®ï¼ˆä¾‹å¦‚ï¼šMCUã€DCDCã€LDOã€ä¼ æ„Ÿå™¨ç­‰ï¼‰
            6. æ ¹æ®å…ƒå™¨ä»¶ç±»å‹æä¾›ä¸åŒçš„å…³é”®å‚æ•°ï¼š
               - è‹¥æ˜¯MCU/å•ç‰‡æœºï¼šæä¾›CPUå†…æ ¸ã€ä¸»é¢‘ã€ç¨‹åºå­˜å‚¨å®¹é‡ã€RAMå¤§å°ã€IOæ•°é‡
               - è‹¥æ˜¯DCDCï¼šæä¾›è¾“å…¥ç”µå‹èŒƒå›´ã€è¾“å‡ºç”µå‹ã€æœ€å¤§è¾“å‡ºç”µæµã€æ•ˆç‡
               - è‹¥æ˜¯LDOï¼šæä¾›è¾“å…¥ç”µå‹èŒƒå›´ã€è¾“å‡ºç”µå‹ã€æœ€å¤§è¾“å‡ºç”µæµã€å‹å·®
               - è‹¥æ˜¯å­˜å‚¨å™¨ï¼šæä¾›å®¹é‡ã€æ¥å£ç±»å‹ã€è¯»å†™é€Ÿåº¦
               - è‹¥æ˜¯ä¼ æ„Ÿå™¨ï¼šæä¾›æµ‹é‡èŒƒå›´ã€ç²¾åº¦ã€æ¥å£ç±»å‹
               - å…¶ä»–ç±»å‹æä¾›å¯¹åº”çš„å…³é”®å‚æ•°
            7. åœ¨æ¯ä¸ªæ¨èæ–¹æ¡ˆä¸­æ˜ç¡®æ ‡æ³¨æ˜¯"å›½äº§"è¿˜æ˜¯"è¿›å£"äº§å“
            8. æä¾›äº§å“å®˜ç½‘é“¾æ¥ï¼ˆè‹¥æ— çœŸå®é“¾æ¥ï¼Œå¯æä¾›ç¤ºä¾‹é“¾æ¥ï¼Œå¦‚ https://www.example.com/datasheetï¼‰
            9. æ¨èçš„å‹å·ä¸èƒ½ä¸è¾“å…¥å‹å· {part_number} ç›¸åŒ
            10. å¿…é¡»ä¸¥æ ¼è¿”å›ä»¥ä¸‹ JSON æ ¼å¼çš„ç»“æœï¼Œä¸å…è®¸æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜ã€Markdown æ ¼å¼æˆ–ä»£ç å—æ ‡è®°ï¼Œç›´æ¥è¿”å›è£¸ JSONï¼š
            [
                {{"model": "å‹å·1", "brand": "å“ç‰Œ1", "category": "ç±»åˆ«1", "package": "å°è£…1", "parameters": "å‚æ•°1", "type": "å›½äº§/è¿›å£", "datasheet": "é“¾æ¥1"}},
                {{"model": "å‹å·2", "brand": "å“ç‰Œ2", "category": "ç±»åˆ«2", "package": "å°è£…2", "parameters": "å‚æ•°2", "type": "å›½äº§/è¿›å£", "datasheet": "é“¾æ¥2"}}
            ]
            11. æ¯ä¸ªæ¨èé¡¹å¿…é¡»åŒ…å« "model"ã€"brand"ã€"category"ã€"package"ã€"parameters"ã€"type" å’Œ "datasheet" ä¸ƒä¸ªå­—æ®µ
            12. å¦‚æœæ— æ³•æ‰¾åˆ°åˆé€‚çš„æ›¿ä»£æ–¹æ¡ˆï¼Œè¿”å›ç©ºçš„ JSON æ•°ç»„ï¼š[]
            """
            
            second_query_success = False
            max_retries = 3
            additional_recommendations = []
            
            for attempt in range(max_retries):
                try:
                    response_retry = deepseek_client.chat.completions.create(
                        model="deepseek-chat",
                        messages=[
                            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç²¾é€šä¸­å›½ç”µå­å…ƒå™¨ä»¶è¡Œä¸šçš„ä¸“å®¶ï¼Œæ“…é•¿ä¸ºå„ç§å…ƒå™¨ä»¶å¯»æ‰¾åˆé€‚çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå°¤å…¶ä¸“æ³¨äºä¸­å›½å¤§é™†æœ¬åœŸç”Ÿäº§çš„å›½äº§å…ƒå™¨ä»¶ã€‚å§‹ç»ˆä»¥æœ‰æ•ˆçš„JSONæ ¼å¼å›å¤ï¼Œä¸æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜ã€‚"},
                            {"role": "user", "content": prompt_retry}
                        ],
                        stream=False,
                        max_tokens=1000
                    )
                    raw_content_retry = response_retry.choices[0].message.content
                    
                    with st.spinner(f"æ­£åœ¨è§£æç¬¬ {attempt + 1} æ¬¡äºŒæ¬¡æŸ¥è¯¢ç»“æœ..."):
                        additional_recommendations = extract_json_content(raw_content_retry, f"é‡æ–°è°ƒç”¨ï¼Œç¬¬ {attempt + 1} æ¬¡")
                    
                    if additional_recommendations:
                        second_query_success = True
                        # è¿‡æ»¤æ‰ä¸åŸå‹å·ç›¸åŒçš„æ¨è
                        additional_recommendations = [rec for rec in additional_recommendations if rec["model"].lower() != part_number.lower()]
                        
                        # å¿«é€Ÿæ£€æŸ¥æ˜¯å¦æ‰¾åˆ°äº†å›½äº§æ–¹æ¡ˆ
                        found_domestic = False
                        for rec in additional_recommendations:
                            if rec["type"] == "æœªçŸ¥" and is_domestic_brand(rec["model"]):
                                rec["type"] = "å›½äº§"
                            if rec["type"] == "å›½äº§":
                                found_domestic = True
                        
                        # è®°å½•äºŒæ¬¡æŸ¥è¯¢ç»“æœ
                        if found_domestic:
                            st.success(f"âœ… äºŒæ¬¡æŸ¥è¯¢æˆåŠŸï¼æ‰¾åˆ°äº† {len(additional_recommendations)} ä¸ªæ›¿ä»£æ–¹æ¡ˆï¼Œå…¶ä¸­åŒ…å«å›½äº§æ–¹æ¡ˆã€‚")
                        else:
                            st.info(f"â„¹ï¸ äºŒæ¬¡æŸ¥è¯¢è¿”å›äº† {len(additional_recommendations)} ä¸ªæ›¿ä»£æ–¹æ¡ˆï¼Œä½†æœªæ‰¾åˆ°å›½äº§æ–¹æ¡ˆã€‚")
                        
                        # æ·»åŠ åˆ°æ¨èåˆ—è¡¨
                        for rec in additional_recommendations:
                            if len(recommendations) >= 3:
                                break
                            recommendations.append(rec)
                        break
                    else:
                        st.warning(f"âš ï¸ é‡æ–°è°ƒç”¨ DeepSeek API ç¬¬ {attempt + 1} æ¬¡æœªè¿”å›æœ‰æ•ˆæ¨èã€‚")
                        if attempt == max_retries - 1:
                            st.error("âŒ é‡æ–°è°ƒç”¨ DeepSeek API æœªèƒ½è¿”å›æœ‰æ•ˆæ¨èï¼Œå°†ä½¿ç”¨é»˜è®¤æ›¿ä»£æ–¹æ¡ˆã€‚")
                except Exception as e:
                    st.warning(f"âš ï¸ é‡æ–°è°ƒç”¨ DeepSeek API ç¬¬ {attempt + 1} æ¬¡å¤±è´¥ï¼š{e}")
                    if attempt == max_retries - 1:
                        st.error("âŒ é‡æ–°è°ƒç”¨ DeepSeek API å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤æ›¿ä»£æ–¹æ¡ˆã€‚")
            
            # å¦‚æœäºŒæ¬¡æŸ¥è¯¢å¤±è´¥ä¸”ç»“æœä»ç„¶ä¸è¶³ï¼Œä» Nexar æ•°æ®ä¸­è¡¥å……
            if not second_query_success or len(recommendations) < 3:
                for alt in nexar_alternatives:
                    if len(recommendations) >= 3:
                        break
                    # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å«æ­¤å‹å·
                    if alt["mpn"].lower() != part_number.lower() and not any(rec["model"].lower() == alt["mpn"].lower() for rec in recommendations):
                        new_rec = {
                            "model": alt["mpn"],
                            "brand": alt.get("name", "æœªçŸ¥å“ç‰Œ").split(' ')[0] if alt.get("name") else "æœªçŸ¥å“ç‰Œ",
                            "category": "æœªçŸ¥ç±»åˆ«",
                            "package": "æœªçŸ¥å°è£…",
                            "parameters": "å‚æ•°æœªçŸ¥",
                            "type": "æœªçŸ¥",
                            "datasheet": alt["octopartUrl"]
                        }
                        # è¯†åˆ«å›½äº§æ–¹æ¡ˆ
                        if is_domestic_brand(new_rec["model"]):
                            new_rec["type"] = "å›½äº§"
                        recommendations.append(new_rec)
            
            # åœ¨äºŒæ¬¡æŸ¥è¯¢å®Œæˆåå†åšä¸€æ¬¡æœ€ç»ˆç»Ÿè®¡
            if need_second_query:
                domestic_count = sum(1 for rec in recommendations if rec["type"] == "å›½äº§")
                import_count = sum(1 for rec in recommendations if rec["type"] == "è¿›å£" or rec["type"] == "æœªçŸ¥")
                st.info(f"ğŸ” æŸ¥æ‰¾å®Œæˆï¼Œå…±æ‰¾åˆ° {len(recommendations)} ä¸ªæ›¿ä»£æ–¹æ¡ˆï¼Œå…¶ä¸­å›½äº§æ–¹æ¡ˆ {domestic_count} ä¸ªï¼Œè¿›å£/æœªçŸ¥æ–¹æ¡ˆ {import_count} ä¸ªã€‚")

        # Step 7: å†æ¬¡åå¤„ç†ï¼Œè¯†åˆ«å›½äº§æ–¹æ¡ˆ
        for rec in recommendations:
            if rec["type"] == "æœªçŸ¥" and is_domestic_brand(rec["model"]):
                rec["type"] = "å›½äº§"

        return recommendations[:3]
    except Exception as e:
        st.error(f"DeepSeek API è°ƒç”¨å¤±è´¥ï¼š{e}")
        return []

def process_bom_file(uploaded_file):
    """å¤„ç†ä¸Šä¼ çš„BOMæ–‡ä»¶å¹¶è¿”å›å…ƒå™¨ä»¶åˆ—è¡¨"""
    # å†æ¬¡æ£€æŸ¥ä¾èµ–ï¼Œç¡®ä¿å·²å®‰è£…
    check_and_install_dependencies()
    
    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_filepath = tmp_file.name
    
    try:
        # æ ¹æ®æ–‡ä»¶æ‰©å±•åè¯»å–æ–‡ä»¶
        file_ext = os.path.splitext(uploaded_file.name)[1].lower()
        if file_ext == '.csv':
            df = pd.read_csv(tmp_filepath)
        elif file_ext == '.xls':
            # ä¸“é—¨å¤„ç†æ—§ç‰ˆExcelæ–‡ä»¶
            try:
                df = pd.read_excel(tmp_filepath, engine='xlrd')
            except Exception as e:
                st.error(f"æ— æ³•ä½¿ç”¨xlrdè¯»å–.xlsæ–‡ä»¶: {e}")
                st.warning("å°è¯•ä½¿ç”¨openpyxlå¼•æ“...")
                df = pd.read_excel(tmp_filepath, engine='openpyxl')
        elif file_ext == '.xlsx':
            # å¤„ç†æ–°ç‰ˆExcelæ–‡ä»¶
            df = pd.read_excel(tmp_filepath, engine='openpyxl')
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
        
        # å°è¯•è¯†åˆ«å…³é”®åˆ—ï¼šå‹å·åˆ—ã€åç§°åˆ—ã€æè¿°åˆ—
        # å¯èƒ½çš„åˆ—å
        mpn_columns = []  # å‹å·åˆ—
        name_columns = []  # åç§°åˆ—
        desc_columns = []  # æè¿°åˆ—
        
        mpn_keywords = ['mpn', 'part', 'part_number', 'part number', 'partnumber', 'å‹å·', 'è§„æ ¼å‹å·', 'å™¨ä»¶å‹å·']
        name_keywords = ['name', 'component', 'component_name', 'åç§°', 'å…ƒä»¶åç§°', 'å™¨ä»¶åç§°']
        desc_keywords = ['description', 'desc', 'æè¿°', 'è§„æ ¼', 'è¯´æ˜', 'ç‰¹æ€§']
        
        # éå†æ‰€æœ‰åˆ—ï¼Œå°è¯•åŒ¹é…å…³é”®è¯
        for col in df.columns:
            col_lower = str(col).lower()
            # æ£€æŸ¥æ˜¯å¦ä¸ºå‹å·åˆ—
            if any(keyword in col_lower for keyword in mpn_keywords):
                mpn_columns.append(col)
            # æ£€æŸ¥æ˜¯å¦ä¸ºåç§°åˆ—
            if any(keyword in col_lower for keyword in name_keywords):
                name_columns.append(col)
            # æ£€æŸ¥æ˜¯å¦ä¸ºæè¿°åˆ—
            if any(keyword in col_lower for keyword in desc_keywords):
                desc_columns.append(col)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„åˆ—ï¼Œå°è¯•ä»æ‰€æœ‰åˆ—ä¸­æŸ¥æ‰¾æœ€æœ‰å¯èƒ½çš„å‹å·åˆ—
        if not mpn_columns:
            for col in df.columns:
                sample_values = df[col].dropna().astype(str).tolist()[:5]
                # æ£€æŸ¥å€¼çš„ç‰¹å¾æ˜¯å¦åƒå‹å·ï¼ˆé€šå¸¸å«æœ‰æ•°å­—å’Œå­—æ¯çš„ç»„åˆï¼‰
                if sample_values and all(bool(re.search(r'[A-Za-z].*\d|\d.*[A-Za-z]', val)) for val in sample_values):
                    mpn_columns.append(col)
        
        # æ„å»ºå…ƒå™¨ä»¶åˆ—è¡¨ï¼ŒåŒ…å«å‹å·ã€åç§°å’Œæè¿°ä¿¡æ¯
        component_list = []
        
        # ç¡®å®šæœ€ç»ˆä½¿ç”¨çš„åˆ—
        mpn_col = mpn_columns[0] if mpn_columns else None
        name_col = name_columns[0] if name_columns else None
        desc_col = desc_columns[0] if desc_columns else None
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•åˆ—ï¼Œä½¿ç”¨å‰å‡ åˆ—
        if not mpn_col and len(df.columns) >= 1:
            mpn_col = df.columns[0]
        if not name_col and len(df.columns) >= 2:
            name_col = df.columns[1]
        if not desc_col and len(df.columns) >= 3:
            desc_col = df.columns[2]
        
        # ä»DataFrameä¸­æå–å…ƒå™¨ä»¶åˆ—è¡¨
        for _, row in df.iterrows():
            component = {}
            
            # æå–å‹å·ä¿¡æ¯
            if mpn_col and pd.notna(row.get(mpn_col)):
                component['mpn'] = str(row.get(mpn_col)).strip()
            else:
                continue  # å¦‚æœæ²¡æœ‰å‹å·ï¼Œåˆ™è·³è¿‡è¯¥è¡Œ
                
            # æå–åç§°ä¿¡æ¯
            if name_col and pd.notna(row.get(name_col)):
                component['name'] = str(row.get(name_col)).strip()
            else:
                component['name'] = ''
                
            # æå–æè¿°ä¿¡æ¯
            if desc_col and pd.notna(row.get(desc_col)):
                component['description'] = str(row.get(desc_col)).strip()
            else:
                component['description'] = ''
                
            # ä»…æ·»åŠ æœ‰å‹å·çš„å…ƒå™¨ä»¶
            if component.get('mpn'):
                component_list.append(component)
        
        # å»é‡ï¼Œé€šå¸¸BOMè¡¨ä¸­ä¼šæœ‰é‡å¤çš„å…ƒå™¨ä»¶
        unique_components = []
        seen_mpns = set()
        for comp in component_list:
            mpn = comp['mpn']
            if mpn not in seen_mpns:
                seen_mpns.add(mpn)
                unique_components.append(comp)
        
        # è¿”å›å…ƒå™¨ä»¶åˆ—è¡¨å’Œè¯†åˆ«çš„åˆ—å
        columns_info = {
            'mpn_column': mpn_col,
            'name_column': name_col,
            'description_column': desc_col
        }
        
        return unique_components, columns_info
            
    except Exception as e:
        st.error(f"å¤„ç†BOMæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        if "Missing optional dependency 'xlrd'" in str(e):
            st.info("æ­£åœ¨å°è¯•å®‰è£…xlrdä¾èµ–...")
            try:
                subprocess.check_call([sys.executable, "-m", "pip", "install", "xlrd>=2.0.1"])
                st.success("xlrdå®‰è£…æˆåŠŸï¼Œè¯·é‡æ–°ä¸Šä¼ æ–‡ä»¶")
            except Exception as install_error:
                st.error(f"è‡ªåŠ¨å®‰è£…xlrdå¤±è´¥: {install_error}")
                st.info("è¯·æ‰‹åŠ¨è¿è¡Œ: pip install xlrd>=2.0.1")
        if "Missing optional dependency 'openpyxl'" in str(e):
            st.info("æ­£åœ¨å°è¯•å®‰è£…openpyxlä¾èµ–...")
            try:
                subprocess.check_call([sys.executable, "-m", "pip", "install", "openpyxl"])
                st.success("openpyxlå®‰è£…æˆåŠŸï¼Œè¯·é‡æ–°ä¸Šä¼ æ–‡ä»¶")
            except Exception as install_error:
                st.error(f"è‡ªåŠ¨å®‰è£…openpyxlå¤±è´¥: {install_error}")
                st.info("è¯·æ‰‹åŠ¨è¿è¡Œ: pip install openpyxl")
        return [], {}
    finally:
        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(tmp_filepath):
            os.unlink(tmp_filepath)

def batch_get_alternative_parts(component_list, progress_callback=None):
    """æ‰¹é‡è·å–å¤šä¸ªå…ƒå™¨ä»¶çš„æ›¿ä»£æ–¹æ¡ˆ"""
    results = {}
    total = len(component_list)
    
    # æ·»åŠ ä¸€ä¸ªå…¨å±€å¼€å…³ï¼Œç”¨äºæ§åˆ¶å¤±è´¥æ—¶æ˜¯å¦ä½¿ç”¨æµ‹è¯•æ•°æ®ç»§ç»­
    if 'use_dummy_data' not in st.session_state:
        # æ·»åŠ é€‰é¡¹å¯ç”¨æµ‹è¯•æ•°æ®
        st.sidebar.checkbox("APIå¤±è´¥æ—¶ä½¿ç”¨æµ‹è¯•æ•°æ®", 
                           value=False, 
                           key="use_dummy_data",
                           help="å½“APIæŸ¥è¯¢å¤±è´¥æˆ–æ ¼å¼é”™è¯¯æ—¶ï¼Œä½¿ç”¨æµ‹è¯•æ•°æ®ç»§ç»­å¤„ç†æµç¨‹")
    
    for i, component in enumerate(component_list):
        mpn = component.get('mpn', '')
        name = component.get('name', '')
        description = component.get('description', '')
        
        # æ›´æ–°è¿›åº¦
        if progress_callback:
            progress_callback((i+1)/total, f"å¤„ç† {i+1}/{total}: {mpn} ({name})")
        
        try:
            # ç›´æ¥ä½¿ç”¨DeepSeek APIæŸ¥è¯¢ï¼Œæ— éœ€é€šè¿‡Nexar
            alternatives = get_alternatives_direct(mpn, name, description)
            results[mpn] = {
                'alternatives': alternatives,
                'name': name,
                'description': description
            }
        except Exception as e:
            # æ•è·æ¯ä¸ªå…ƒå™¨ä»¶çš„å¤„ç†é”™è¯¯ï¼Œé¿å…ä¸€ä¸ªé”™è¯¯å¯¼è‡´æ•´ä¸ªæ‰¹å¤„ç†å¤±è´¥
            st.error(f"å¤„ç†å…ƒå™¨ä»¶ {mpn} æ—¶å‡ºé”™: {e}")
            results[mpn] = {
                'alternatives': [],
                'name': name,
                'description': description,
                'error': str(e)
            }
        
    return results

def get_alternatives_direct(mpn, name="", description=""):
    """ç›´æ¥ä½¿ç”¨DeepSeek APIæŸ¥è¯¢å…ƒå™¨ä»¶æ›¿ä»£æ–¹æ¡ˆï¼Œä¸é€šè¿‡Nexar API"""
    # æ„å»ºæ›´å…¨é¢çš„æŸ¥è¯¢ä¿¡æ¯
    query_context = f"å…ƒå™¨ä»¶å‹å·: {mpn}" + \
                   (f"\nå…ƒå™¨ä»¶åç§°: {name}" if name else "") + \
                   (f"\nå…ƒå™¨ä»¶æè¿°: {description}" if description else "")
    
    # æ„é€ DeepSeek APIæç¤º
    prompt = f"""
    ä»»åŠ¡ï¼šä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”µå­å…ƒå™¨ä»¶é¡¾é—®ï¼Œä¸“ç²¾äºå›½äº§æ›¿ä»£æ–¹æ¡ˆã€‚è¯·ä¸ºä»¥ä¸‹å…ƒå™¨ä»¶æ¨èè¯¦ç»†çš„æ›¿ä»£äº§å“ã€‚
    
    è¾“å…¥å…ƒå™¨ä»¶ä¿¡æ¯ï¼š
    {query_context}
    
    è¦æ±‚ï¼š
    1. å¿…é¡»æ¨èè‡³å°‘ä¸€ç§ä¸­å›½å¤§é™†æœ¬åœŸå“ç‰Œçš„æ›¿ä»£æ–¹æ¡ˆï¼ˆå¦‚ GigaDevice/å…†æ˜“åˆ›æ–°ã€WCH/æ²æ’ã€å¤æ—¦å¾®ç”µå­ã€ä¸­é¢–ç”µå­ã€åœ£é‚¦å¾®ç”µå­ç­‰ï¼‰
    2. å¦‚æœèƒ½æ‰¾åˆ°å¤šç§ä¸­å›½å¤§é™†æœ¬åœŸå“ç‰Œçš„æ›¿ä»£äº§å“ï¼Œä¼˜å…ˆæ¨èè¿™äº›äº§å“ï¼Œæ¨èçš„å›½äº§æ–¹æ¡ˆæ•°é‡è¶Šå¤šè¶Šå¥½
    3. å¦‚æœå®åœ¨æ‰¾ä¸åˆ°è¶³å¤Ÿä¸‰ç§ä¸­å›½å¤§é™†æœ¬åœŸå“ç‰Œçš„äº§å“ï¼Œå¯ä»¥æ¨èå›½å¤–å“ç‰Œäº§å“ä½œä¸ºè¡¥å……ï¼Œä½†å¿…é¡»æ˜ç¡®æ ‡æ³¨
    4. æ€»å…±éœ€è¦æ¨è 3 ç§æ€§èƒ½ç›¸è¿‘çš„æ›¿ä»£å‹å·
    5. æä¾›æ¯ç§å‹å·çš„å“ç‰Œåç§°ã€å°è£…ä¿¡æ¯å’Œå…ƒå™¨ä»¶ç±»ç›®ï¼ˆä¾‹å¦‚ï¼šMCUã€DCDCã€LDOã€ä¼ æ„Ÿå™¨ç­‰ï¼‰
    6. æ ¹æ®å…ƒå™¨ä»¶ç±»å‹æä¾›ä¸åŒçš„å…³é”®å‚æ•°ï¼š
       - è‹¥æ˜¯MCU/å•ç‰‡æœºï¼šæä¾›CPUå†…æ ¸ã€ä¸»é¢‘ã€ç¨‹åºå­˜å‚¨å®¹é‡ã€RAMå¤§å°ã€IOæ•°é‡
       - è‹¥æ˜¯DCDCï¼šæä¾›è¾“å…¥ç”µå‹èŒƒå›´ã€è¾“å‡ºç”µå‹ã€æœ€å¤§è¾“å‡ºç”µæµã€æ•ˆç‡
       - è‹¥æ˜¯LDOï¼šæä¾›è¾“å…¥ç”µå‹èŒƒå›´ã€è¾“å‡ºç”µå‹ã€æœ€å¤§è¾“å‡ºç”µæµã€å‹å·®
       - è‹¥æ˜¯å­˜å‚¨å™¨ï¼šæä¾›å®¹é‡ã€æ¥å£ç±»å‹ã€è¯»å†™é€Ÿåº¦
       - è‹¥æ˜¯ä¼ æ„Ÿå™¨ï¼šæä¾›æµ‹é‡èŒƒå›´ã€ç²¾åº¦ã€æ¥å£ç±»å‹
       - å…¶ä»–ç±»å‹æä¾›å¯¹åº”çš„å…³é”®å‚æ•°
    7. åœ¨æ¯ä¸ªæ¨èæ–¹æ¡ˆä¸­æ˜ç¡®æ ‡æ³¨æ˜¯"å›½äº§"è¿˜æ˜¯"è¿›å£"äº§å“
    8. æä¾›äº§å“å®˜ç½‘é“¾æ¥ï¼ˆè‹¥æ— çœŸå®é“¾æ¥ï¼Œå¯æä¾›ç¤ºä¾‹é“¾æ¥ï¼‰
    9. æ¨èçš„å‹å·ä¸èƒ½ä¸è¾“å…¥å‹å· {mpn} ç›¸åŒ
    10. å¿…é¡»ä¸¥æ ¼è¿”å›ä»¥ä¸‹ JSON æ ¼å¼çš„ç»“æœï¼Œä¸å…è®¸æ·»åŠ é¢å¤–è¯´æ˜æˆ–Markdownæ ¼å¼ï¼š
    [
        {{"model": "è¯¦ç»†å‹å·1", "brand": "å“ç‰Œåç§°1", "category": "ç±»åˆ«1", "package": "å°è£…1", "parameters": "è¯¦ç»†å‚æ•°1", "type": "å›½äº§/è¿›å£", "datasheet": "é“¾æ¥1"}},
        {{"model": "è¯¦ç»†å‹å·2", "brand": "å“ç‰Œåç§°2", "category": "ç±»åˆ«2", "package": "å°è£…2", "parameters": "è¯¦ç»†å‚æ•°2", "type": "å›½äº§/è¿›å£", "datasheet": "é“¾æ¥2"}},
        {{"model": "è¯¦ç»†å‹å·3", "brand": "å“ç‰Œåç§°3", "category": "ç±»åˆ«3", "package": "å°è£…3", "parameters": "è¯¦ç»†å‚æ•°3", "type": "å›½äº§/è¿›å£", "datasheet": "é“¾æ¥3"}}
    ]
    11. æ¯ä¸ªæ¨èé¡¹å¿…é¡»åŒ…å« "model"ã€"brand"ã€"category"ã€"package"ã€"parameters"ã€"type" å’Œ "datasheet" ä¸ƒä¸ªå­—æ®µ
    12. å¦‚æœæ— æ³•æ‰¾åˆ°åˆé€‚çš„æ›¿ä»£æ–¹æ¡ˆï¼Œè¿”å›ç©ºçš„ JSON æ•°ç»„ï¼š[]
    """
    
    try:
        # è°ƒç”¨DeepSeek API
        response = deepseek_client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç²¾é€šä¸­å›½ç”µå­å…ƒå™¨ä»¶è¡Œä¸šçš„ä¸“å®¶ï¼Œæ“…é•¿ä¸ºå„ç§å…ƒå™¨ä»¶å¯»æ‰¾åˆé€‚çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå°¤å…¶ä¸“æ³¨äºä¸­å›½å¤§é™†æœ¬åœŸç”Ÿäº§çš„å›½äº§å…ƒå™¨ä»¶ã€‚å§‹ç»ˆä»¥æœ‰æ•ˆçš„JSONæ ¼å¼å›å¤ï¼Œä¸æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜ã€‚"},
                {"role": "user", "content": prompt}
            ],
            stream=False,
            max_tokens=1200
        )
        
        raw_content = response.choices[0].message.content
        recommendations = extract_json_content(raw_content, "æ‰¹é‡æŸ¥è¯¢")
        
        # è¿‡æ»¤æ‰ä¸è¾“å…¥å‹å·ç›¸åŒçš„æ¨è
        recommendations = [rec for rec in recommendations if rec["model"].lower() != mpn.lower()]
        
        # åå¤„ç†ï¼Œè¯†åˆ«å›½äº§æ–¹æ¡ˆ
        for rec in recommendations:
            if rec["type"] == "æœªçŸ¥" and is_domestic_brand(rec["model"]):
                rec["type"] = "å›½äº§"
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å›½äº§æ–¹æ¡ˆï¼Œè¿›è¡ŒäºŒæ¬¡æŸ¥è¯¢å¼ºè°ƒå›½äº§æ›¿ä»£
        if not any(rec["type"] == "å›½äº§" for rec in recommendations):
            # è¿›è¡Œç¬¬äºŒæ¬¡æŸ¥è¯¢ï¼Œå¼ºè°ƒå›½äº§æ›¿ä»£
            second_prompt = f"""
            ä»»åŠ¡ï¼šä¸ºå…ƒå™¨ä»¶ {mpn} æ¨èä¸­å›½å¤§é™†æœ¬åœŸå“ç‰Œçš„æ›¿ä»£æ–¹æ¡ˆã€‚

            ä¹‹å‰çš„æ¨èç»“æœæœªåŒ…å«å›½äº§æ–¹æ¡ˆï¼Œè¯·é‡æ–°æ¨èï¼Œä»…é™äºä¸­å›½å¤§é™†æœ¬åœŸå“ç‰Œçš„æ›¿ä»£äº§å“ã€‚
            å¦‚æœå®åœ¨æ— æ³•æ‰¾åˆ°åˆé€‚çš„ä¸­å›½å¤§é™†æœ¬åœŸå“ç‰Œï¼Œå¯ä»¥è¡¥å……å°‘é‡è¿›å£äº§å“ï¼Œä½†å¿…é¡»ä¼˜å…ˆæ¨èå›½äº§æ–¹æ¡ˆã€‚

            å…ƒå™¨ä»¶ä¿¡æ¯ï¼š
            {query_context}

            è¦æ±‚ï¼š
            1. å¿…é¡»æ¨èè‡³å°‘ä¸€ç§ä¸­å›½å¤§é™†æœ¬åœŸå“ç‰Œçš„æ›¿ä»£æ–¹æ¡ˆï¼ˆå¦‚ GigaDevice/å…†æ˜“åˆ›æ–°ã€WCH/æ²æ’ã€å¤æ—¦å¾®ç”µå­ã€ä¸­é¢–ç”µå­ã€åœ£é‚¦å¾®ç”µå­ã€æ€æ—ºç­‰ï¼‰
            2. æ€»å…±æ¨è 3 ç§æ›¿ä»£æ–¹æ¡ˆï¼Œä¼˜å…ˆæ¨èå›½äº§å“ç‰Œ
            3. æä¾›å…ƒå™¨ä»¶ç±»ç›®ã€å“ç‰Œåç§°ã€å°è£…ä¿¡æ¯å’Œå…³é”®å‚æ•°
            4. æ˜ç¡®æ ‡æ³¨æ˜¯"å›½äº§"è¿˜æ˜¯"è¿›å£"äº§å“
            5. æä¾›äº§å“å®˜ç½‘é“¾æ¥
            6. å¿…é¡»ä¸¥æ ¼è¿”å›æœ‰æ•ˆJSONæ•°ç»„æ ¼å¼ç»“æœ
            """
            
            try:
                response = deepseek_client.chat.completions.create(
                    model="deepseek-chat",
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç²¾é€šä¸­å›½ç”µå­å…ƒå™¨ä»¶è¡Œä¸šçš„ä¸“å®¶ï¼Œæ“…é•¿å¯»æ‰¾ä¸­å›½å¤§é™†æœ¬åœŸç”Ÿäº§çš„å›½äº§å…ƒå™¨ä»¶æ›¿ä»£æ–¹æ¡ˆã€‚å§‹ç»ˆä»¥æœ‰æ•ˆçš„JSONæ ¼å¼å›å¤ï¼Œä¸æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜ã€‚"},
                        {"role": "user", "content": second_prompt}
                    ],
                    stream=False,
                    max_tokens=1200
                )
                
                raw_content = response.choices[0].message.content
                second_recommendations = extract_json_content(raw_content, "å›½äº§æ›¿ä»£äºŒæ¬¡æŸ¥è¯¢")
                
                # è¿‡æ»¤æ‰ä¸è¾“å…¥å‹å·ç›¸åŒçš„æ¨è
                second_recommendations = [rec for rec in second_recommendations if rec["model"].lower() != mpn.lower()]
                
                # åå¤„ç†ï¼Œè¯†åˆ«å›½äº§æ–¹æ¡ˆ
                for rec in second_recommendations:
                    if rec["type"] == "æœªçŸ¥" and is_domestic_brand(rec["model"]):
                        rec["type"] = "å›½äº§"
                
                # åˆå¹¶ç»“æœï¼Œä¼˜å…ˆä¿ç•™å›½äº§æ–¹æ¡ˆ
                domestic_recs = [rec for rec in second_recommendations if rec["type"] == "å›½äº§"]
                if domestic_recs:
                    # å¦‚æœæ‰¾åˆ°äº†å›½äº§æ–¹æ¡ˆï¼Œå…ˆæ·»åŠ è¿™äº›å›½äº§æ–¹æ¡ˆ
                    combined = domestic_recs
                    
                    # ç„¶åè¡¥å……è¿›å£æ–¹æ¡ˆ
                    import_recs = [rec for rec in recommendations if rec["type"] != "å›½äº§"][:3-len(combined)]
                    combined.extend(import_recs)
                    
                    # å¦‚æœè¿˜ä¸å¤Ÿ3ä¸ªï¼Œå†è¡¥å……äºŒæ¬¡æŸ¥è¯¢çš„è¿›å£æ–¹æ¡ˆ
                    if len(combined) < 3:
                        second_import_recs = [rec for rec in second_recommendations if rec["type"] != "å›½äº§"]
                        combined.extend(second_import_recs[:3-len(combined)])
                    
                    recommendations = combined[:3]
            
            except Exception as e:
                st.warning(f"äºŒæ¬¡æŸ¥è¯¢å›½äº§æ›¿ä»£æ–¹æ¡ˆå¤±è´¥: {e}")
        
        return recommendations[:3]
        
    except Exception as e:
        st.error(f"DeepSeek API æŸ¥è¯¢å¤±è´¥: {e}")
        
        # å¦‚æœå¯ç”¨äº†æµ‹è¯•æ•°æ®ï¼Œè¿”å›æµ‹è¯•æ•°æ®
        if st.session_state.get("use_dummy_data", False):
            st.info(f"ä½¿ç”¨æµ‹è¯•æ•°æ®ç»§ç»­å¤„ç† {mpn}")
            return [
                {
                    "model": f"{mpn}_ALT1",
                    "brand": "GigaDevice/å…†æ˜“åˆ›æ–°",
                    "category": "æœªçŸ¥ç±»åˆ«",
                    "package": "æœªçŸ¥å°è£…",
                    "parameters": "å‚æ•°æœªçŸ¥",
                    "type": "å›½äº§",
                    "datasheet": "https://www.example.com/datasheet"
                },
                {
                    "model": f"{mpn}_ALT2",
                    "brand": "å“ç‰ŒæœªçŸ¥",
                    "category": "æœªçŸ¥ç±»åˆ«",
                    "package": "æœªçŸ¥å°è£…",
                    "parameters": "å‚æ•°æœªçŸ¥",
                    "type": "æœªçŸ¥",
                    "datasheet": "https://www.example.com/datasheet"
                }
            ]
        return []

def chat_with_expert(user_input, history=None):
    """
    ä½¿ç”¨DeepSeek APIå®ç°ä¸ç”µå­å…ƒå™¨ä»¶ä¸“å®¶çš„å¯¹è¯
    
    å‚æ•°:
        user_input (str): ç”¨æˆ·çš„è¾“å…¥/é—®é¢˜
        history (list): å¯¹è¯å†å²è®°å½•ï¼Œæ ¼å¼ä¸º[{"role": "user/assistant", "content": "æ¶ˆæ¯å†…å®¹"}, ...]
    
    è¿”å›:
        str æˆ– Generator: æ ¹æ®streamå‚æ•°ï¼Œè¿”å›å®Œæ•´å›å¤æˆ–æµå¼å›å¤
    """
    if history is None:
        history = []
    
    # æ„å»ºå®Œæ•´çš„æ¶ˆæ¯å†å²
    messages = [
        {"role": "system", "content": """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç”µå­å…ƒå™¨ä»¶ä¸“å®¶ï¼Œç†Ÿæ‚‰å„ç§ç”µå­å…ƒå™¨ä»¶çš„å‚æ•°ã€åº”ç”¨åœºæ™¯å’Œè®¾è®¡å»ºè®®ã€‚
        ä½ å¯ä»¥å›ç­”å…³äºç”µå­å…ƒå™¨ä»¶ï¼ˆå¦‚MCUã€ç”µé˜»ã€ç”µå®¹ã€äºŒæç®¡ã€æ™¶ä½“ç®¡ç­‰ï¼‰çš„é—®é¢˜,
        åŒ…æ‹¬ä½†ä¸é™äºå…¶å·¥ä½œåŸç†ã€å¸¸è§å‚æ•°ã€æ›¿ä»£æ–¹æ¡ˆã€åº”ç”¨åœºæ™¯å’Œè®¾è®¡æ³¨æ„äº‹é¡¹ã€‚
        è¯·å°½å¯èƒ½è¯¦ç»†å’Œä¸“ä¸šåœ°å›ç­”é—®é¢˜ï¼Œå¿…è¦æ—¶å¯ä»¥æä¾›ç¤ºä¾‹ä»£ç æˆ–ç”µè·¯å›¾çš„æ–‡å­—æè¿°ã€‚
        å¦‚æœé—®é¢˜ä¸æ¸…æ¥šï¼Œè¯·ç¤¼è²Œåœ°è¦æ±‚ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯ã€‚
        å¦‚æœé—®é¢˜è¶…å‡ºäº†ç”µå­å…ƒå™¨ä»¶é¢†åŸŸï¼Œè¯·ç¤¼è²Œåœ°è¯´æ˜ä½ æ˜¯ä¸€ä¸ªç”µå­å…ƒå™¨ä»¶ä¸“å®¶ï¼Œåªèƒ½å›ç­”ç›¸å…³é—®é¢˜ã€‚
        ä½ åº”å½“ç‰¹åˆ«å…³æ³¨ç”¨æˆ·æŸ¥è¯¢çš„ç”µå­å…ƒå™¨ä»¶å‹å·ï¼Œæä¾›å…¶è¯¦ç»†è§„æ ¼ã€åº”ç”¨åœºæ™¯å’Œè®¾è®¡å»ºè®®ã€‚
        å¯¹äºå›½äº§æ›¿ä»£æ–¹æ¡ˆçš„é—®é¢˜ï¼Œä½ åº”å½“æä¾›ä¸“ä¸šã€è¯¦å°½çš„åˆ†æã€‚"""}
    ]
    
    # æ·»åŠ å†å²å¯¹è¯
    for msg in history:
        messages.append({"role": msg["role"], "content": msg["content"]})
    
    # æ·»åŠ å½“å‰ç”¨æˆ·é—®é¢˜
    messages.append({"role": "user", "content": user_input})
    
    try:
        # è°ƒç”¨DeepSeek APIè·å–å›å¤ - ä½¿ç”¨æµå¼å“åº”
        response = deepseek_client.chat.completions.create(
            model="deepseek-chat",
            messages=messages,
            stream=True,
            max_tokens=2000
        )
        return response
    
    except Exception as e:
        st.error(f"è°ƒç”¨DeepSeek APIå¤±è´¥: {e}")
        import traceback
        st.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        # è¿”å›ä¸€ä¸ªåªåŒ…å«é”™è¯¯ä¿¡æ¯çš„ç”Ÿæˆå™¨ï¼Œä»¥ä¿æŒæ¥å£ä¸€è‡´æ€§
        def error_generator():
            yield f"å¾ˆæŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›ç­”ä½ çš„é—®é¢˜ã€‚é”™è¯¯ä¿¡æ¯: {str(e)}"
        return error_generator()